{
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "view-in-github",
        "colab_type": "text"
      },
      "source": [
        "<a href=\"https://colab.research.google.com/github/unknownexplosion/Sentiment-analysis/blob/main/ABSA_Fine_Tuning_Colab.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "tk6hGrE4pCtv"
      },
      "source": [
        "# Fine-Tune ABSA Model on Google Colab\n",
        "\n",
        "This notebook allows you to use Google's free GPUs to fine-tune your DeBERTa model for Aspect-Based Sentiment Analysis."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 1,
      "metadata": {
        "id": "AwFH5lrZpCtx",
        "outputId": "34a45bfd-0074-4844-8601-cc81f510ec20",
        "colab": {
          "base_uri": "https://localhost:8080/"
        }
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Cloning into 'Sentiment-analysis'...\n",
            "remote: Enumerating objects: 53, done.\u001b[K\n",
            "remote: Counting objects: 100% (53/53), done.\u001b[K\n",
            "remote: Compressing objects: 100% (37/37), done.\u001b[K\n",
            "remote: Total 53 (delta 23), reused 46 (delta 16), pack-reused 0 (from 0)\u001b[K\n",
            "Receiving objects: 100% (53/53), 1.10 MiB | 9.29 MiB/s, done.\n",
            "Resolving deltas: 100% (23/23), done.\n",
            "/content/Sentiment-analysis\n"
          ]
        }
      ],
      "source": [
        "# 1. Clone your Repository\n",
        "!git clone https://github.com/unknownexplosion/Sentiment-analysis.git\n",
        "%cd Sentiment-analysis"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 2,
      "metadata": {
        "id": "VmWMx98wpCty",
        "outputId": "a4777338-8fa3-4bda-d723-4c1aa23500e8",
        "colab": {
          "base_uri": "https://localhost:8080/"
        }
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Requirement already satisfied: pandas in /usr/local/lib/python3.12/dist-packages (from -r requirements.txt (line 1)) (2.2.2)\n",
            "Requirement already satisfied: numpy in /usr/local/lib/python3.12/dist-packages (from -r requirements.txt (line 2)) (2.0.2)\n",
            "Requirement already satisfied: torch in /usr/local/lib/python3.12/dist-packages (from -r requirements.txt (line 3)) (2.9.0+cu126)\n",
            "Requirement already satisfied: transformers in /usr/local/lib/python3.12/dist-packages (from -r requirements.txt (line 4)) (4.57.2)\n",
            "Requirement already satisfied: scipy in /usr/local/lib/python3.12/dist-packages (from -r requirements.txt (line 5)) (1.16.3)\n",
            "Collecting langdetect (from -r requirements.txt (line 6))\n",
            "  Downloading langdetect-1.0.9.tar.gz (981 kB)\n",
            "\u001b[?25l     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m0.0/981.5 kB\u001b[0m \u001b[31m?\u001b[0m eta \u001b[36m-:--:--\u001b[0m\r\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m981.5/981.5 kB\u001b[0m \u001b[31m54.4 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25h  Preparing metadata (setup.py) ... \u001b[?25l\u001b[?25hdone\n",
            "Collecting deep-translator (from -r requirements.txt (line 7))\n",
            "  Downloading deep_translator-1.11.4-py3-none-any.whl.metadata (30 kB)\n",
            "Requirement already satisfied: matplotlib in /usr/local/lib/python3.12/dist-packages (from -r requirements.txt (line 8)) (3.10.0)\n",
            "Requirement already satisfied: seaborn in /usr/local/lib/python3.12/dist-packages (from -r requirements.txt (line 9)) (0.13.2)\n",
            "Requirement already satisfied: openpyxl in /usr/local/lib/python3.12/dist-packages (from -r requirements.txt (line 10)) (3.1.5)\n",
            "Requirement already satisfied: tabulate in /usr/local/lib/python3.12/dist-packages (from -r requirements.txt (line 11)) (0.9.0)\n",
            "Requirement already satisfied: spacy in /usr/local/lib/python3.12/dist-packages (from -r requirements.txt (line 12)) (3.8.11)\n",
            "Requirement already satisfied: nbformat in /usr/local/lib/python3.12/dist-packages (from -r requirements.txt (line 13)) (5.10.4)\n",
            "Collecting streamlit (from -r requirements.txt (line 14))\n",
            "  Downloading streamlit-1.52.0-py3-none-any.whl.metadata (9.8 kB)\n",
            "Requirement already satisfied: plotly in /usr/local/lib/python3.12/dist-packages (from -r requirements.txt (line 15)) (5.24.1)\n",
            "Requirement already satisfied: tqdm in /usr/local/lib/python3.12/dist-packages (from -r requirements.txt (line 16)) (4.67.1)\n",
            "Requirement already satisfied: scikit-learn in /usr/local/lib/python3.12/dist-packages (from -r requirements.txt (line 17)) (1.6.1)\n",
            "Requirement already satisfied: accelerate in /usr/local/lib/python3.12/dist-packages (from -r requirements.txt (line 18)) (1.12.0)\n",
            "Requirement already satisfied: sentencepiece in /usr/local/lib/python3.12/dist-packages (from -r requirements.txt (line 19)) (0.2.1)\n",
            "Requirement already satisfied: python-dateutil>=2.8.2 in /usr/local/lib/python3.12/dist-packages (from pandas->-r requirements.txt (line 1)) (2.9.0.post0)\n",
            "Requirement already satisfied: pytz>=2020.1 in /usr/local/lib/python3.12/dist-packages (from pandas->-r requirements.txt (line 1)) (2025.2)\n",
            "Requirement already satisfied: tzdata>=2022.7 in /usr/local/lib/python3.12/dist-packages (from pandas->-r requirements.txt (line 1)) (2025.2)\n",
            "Requirement already satisfied: filelock in /usr/local/lib/python3.12/dist-packages (from torch->-r requirements.txt (line 3)) (3.20.0)\n",
            "Requirement already satisfied: typing-extensions>=4.10.0 in /usr/local/lib/python3.12/dist-packages (from torch->-r requirements.txt (line 3)) (4.15.0)\n",
            "Requirement already satisfied: setuptools in /usr/local/lib/python3.12/dist-packages (from torch->-r requirements.txt (line 3)) (75.2.0)\n",
            "Requirement already satisfied: sympy>=1.13.3 in /usr/local/lib/python3.12/dist-packages (from torch->-r requirements.txt (line 3)) (1.14.0)\n",
            "Requirement already satisfied: networkx>=2.5.1 in /usr/local/lib/python3.12/dist-packages (from torch->-r requirements.txt (line 3)) (3.6)\n",
            "Requirement already satisfied: jinja2 in /usr/local/lib/python3.12/dist-packages (from torch->-r requirements.txt (line 3)) (3.1.6)\n",
            "Requirement already satisfied: fsspec>=0.8.5 in /usr/local/lib/python3.12/dist-packages (from torch->-r requirements.txt (line 3)) (2025.3.0)\n",
            "Requirement already satisfied: nvidia-cuda-nvrtc-cu12==12.6.77 in /usr/local/lib/python3.12/dist-packages (from torch->-r requirements.txt (line 3)) (12.6.77)\n",
            "Requirement already satisfied: nvidia-cuda-runtime-cu12==12.6.77 in /usr/local/lib/python3.12/dist-packages (from torch->-r requirements.txt (line 3)) (12.6.77)\n",
            "Requirement already satisfied: nvidia-cuda-cupti-cu12==12.6.80 in /usr/local/lib/python3.12/dist-packages (from torch->-r requirements.txt (line 3)) (12.6.80)\n",
            "Requirement already satisfied: nvidia-cudnn-cu12==9.10.2.21 in /usr/local/lib/python3.12/dist-packages (from torch->-r requirements.txt (line 3)) (9.10.2.21)\n",
            "Requirement already satisfied: nvidia-cublas-cu12==12.6.4.1 in /usr/local/lib/python3.12/dist-packages (from torch->-r requirements.txt (line 3)) (12.6.4.1)\n",
            "Requirement already satisfied: nvidia-cufft-cu12==11.3.0.4 in /usr/local/lib/python3.12/dist-packages (from torch->-r requirements.txt (line 3)) (11.3.0.4)\n",
            "Requirement already satisfied: nvidia-curand-cu12==10.3.7.77 in /usr/local/lib/python3.12/dist-packages (from torch->-r requirements.txt (line 3)) (10.3.7.77)\n",
            "Requirement already satisfied: nvidia-cusolver-cu12==11.7.1.2 in /usr/local/lib/python3.12/dist-packages (from torch->-r requirements.txt (line 3)) (11.7.1.2)\n",
            "Requirement already satisfied: nvidia-cusparse-cu12==12.5.4.2 in /usr/local/lib/python3.12/dist-packages (from torch->-r requirements.txt (line 3)) (12.5.4.2)\n",
            "Requirement already satisfied: nvidia-cusparselt-cu12==0.7.1 in /usr/local/lib/python3.12/dist-packages (from torch->-r requirements.txt (line 3)) (0.7.1)\n",
            "Requirement already satisfied: nvidia-nccl-cu12==2.27.5 in /usr/local/lib/python3.12/dist-packages (from torch->-r requirements.txt (line 3)) (2.27.5)\n",
            "Requirement already satisfied: nvidia-nvshmem-cu12==3.3.20 in /usr/local/lib/python3.12/dist-packages (from torch->-r requirements.txt (line 3)) (3.3.20)\n",
            "Requirement already satisfied: nvidia-nvtx-cu12==12.6.77 in /usr/local/lib/python3.12/dist-packages (from torch->-r requirements.txt (line 3)) (12.6.77)\n",
            "Requirement already satisfied: nvidia-nvjitlink-cu12==12.6.85 in /usr/local/lib/python3.12/dist-packages (from torch->-r requirements.txt (line 3)) (12.6.85)\n",
            "Requirement already satisfied: nvidia-cufile-cu12==1.11.1.6 in /usr/local/lib/python3.12/dist-packages (from torch->-r requirements.txt (line 3)) (1.11.1.6)\n",
            "Requirement already satisfied: triton==3.5.0 in /usr/local/lib/python3.12/dist-packages (from torch->-r requirements.txt (line 3)) (3.5.0)\n",
            "Requirement already satisfied: huggingface-hub<1.0,>=0.34.0 in /usr/local/lib/python3.12/dist-packages (from transformers->-r requirements.txt (line 4)) (0.36.0)\n",
            "Requirement already satisfied: packaging>=20.0 in /usr/local/lib/python3.12/dist-packages (from transformers->-r requirements.txt (line 4)) (25.0)\n",
            "Requirement already satisfied: pyyaml>=5.1 in /usr/local/lib/python3.12/dist-packages (from transformers->-r requirements.txt (line 4)) (6.0.3)\n",
            "Requirement already satisfied: regex!=2019.12.17 in /usr/local/lib/python3.12/dist-packages (from transformers->-r requirements.txt (line 4)) (2025.11.3)\n",
            "Requirement already satisfied: requests in /usr/local/lib/python3.12/dist-packages (from transformers->-r requirements.txt (line 4)) (2.32.4)\n",
            "Requirement already satisfied: tokenizers<=0.23.0,>=0.22.0 in /usr/local/lib/python3.12/dist-packages (from transformers->-r requirements.txt (line 4)) (0.22.1)\n",
            "Requirement already satisfied: safetensors>=0.4.3 in /usr/local/lib/python3.12/dist-packages (from transformers->-r requirements.txt (line 4)) (0.7.0)\n",
            "Requirement already satisfied: six in /usr/local/lib/python3.12/dist-packages (from langdetect->-r requirements.txt (line 6)) (1.17.0)\n",
            "Requirement already satisfied: beautifulsoup4<5.0.0,>=4.9.1 in /usr/local/lib/python3.12/dist-packages (from deep-translator->-r requirements.txt (line 7)) (4.13.5)\n",
            "Requirement already satisfied: contourpy>=1.0.1 in /usr/local/lib/python3.12/dist-packages (from matplotlib->-r requirements.txt (line 8)) (1.3.3)\n",
            "Requirement already satisfied: cycler>=0.10 in /usr/local/lib/python3.12/dist-packages (from matplotlib->-r requirements.txt (line 8)) (0.12.1)\n",
            "Requirement already satisfied: fonttools>=4.22.0 in /usr/local/lib/python3.12/dist-packages (from matplotlib->-r requirements.txt (line 8)) (4.60.1)\n",
            "Requirement already satisfied: kiwisolver>=1.3.1 in /usr/local/lib/python3.12/dist-packages (from matplotlib->-r requirements.txt (line 8)) (1.4.9)\n",
            "Requirement already satisfied: pillow>=8 in /usr/local/lib/python3.12/dist-packages (from matplotlib->-r requirements.txt (line 8)) (11.3.0)\n",
            "Requirement already satisfied: pyparsing>=2.3.1 in /usr/local/lib/python3.12/dist-packages (from matplotlib->-r requirements.txt (line 8)) (3.2.5)\n",
            "Requirement already satisfied: et-xmlfile in /usr/local/lib/python3.12/dist-packages (from openpyxl->-r requirements.txt (line 10)) (2.0.0)\n",
            "Requirement already satisfied: spacy-legacy<3.1.0,>=3.0.11 in /usr/local/lib/python3.12/dist-packages (from spacy->-r requirements.txt (line 12)) (3.0.12)\n",
            "Requirement already satisfied: spacy-loggers<2.0.0,>=1.0.0 in /usr/local/lib/python3.12/dist-packages (from spacy->-r requirements.txt (line 12)) (1.0.5)\n",
            "Requirement already satisfied: murmurhash<1.1.0,>=0.28.0 in /usr/local/lib/python3.12/dist-packages (from spacy->-r requirements.txt (line 12)) (1.0.15)\n",
            "Requirement already satisfied: cymem<2.1.0,>=2.0.2 in /usr/local/lib/python3.12/dist-packages (from spacy->-r requirements.txt (line 12)) (2.0.13)\n",
            "Requirement already satisfied: preshed<3.1.0,>=3.0.2 in /usr/local/lib/python3.12/dist-packages (from spacy->-r requirements.txt (line 12)) (3.0.12)\n",
            "Requirement already satisfied: thinc<8.4.0,>=8.3.4 in /usr/local/lib/python3.12/dist-packages (from spacy->-r requirements.txt (line 12)) (8.3.10)\n",
            "Requirement already satisfied: wasabi<1.2.0,>=0.9.1 in /usr/local/lib/python3.12/dist-packages (from spacy->-r requirements.txt (line 12)) (1.1.3)\n",
            "Requirement already satisfied: srsly<3.0.0,>=2.4.3 in /usr/local/lib/python3.12/dist-packages (from spacy->-r requirements.txt (line 12)) (2.5.2)\n",
            "Requirement already satisfied: catalogue<2.1.0,>=2.0.6 in /usr/local/lib/python3.12/dist-packages (from spacy->-r requirements.txt (line 12)) (2.0.10)\n",
            "Requirement already satisfied: weasel<0.5.0,>=0.4.2 in /usr/local/lib/python3.12/dist-packages (from spacy->-r requirements.txt (line 12)) (0.4.3)\n",
            "Requirement already satisfied: typer-slim<1.0.0,>=0.3.0 in /usr/local/lib/python3.12/dist-packages (from spacy->-r requirements.txt (line 12)) (0.20.0)\n",
            "Requirement already satisfied: pydantic!=1.8,!=1.8.1,<3.0.0,>=1.7.4 in /usr/local/lib/python3.12/dist-packages (from spacy->-r requirements.txt (line 12)) (2.12.3)\n",
            "Requirement already satisfied: fastjsonschema>=2.15 in /usr/local/lib/python3.12/dist-packages (from nbformat->-r requirements.txt (line 13)) (2.21.2)\n",
            "Requirement already satisfied: jsonschema>=2.6 in /usr/local/lib/python3.12/dist-packages (from nbformat->-r requirements.txt (line 13)) (4.25.1)\n",
            "Requirement already satisfied: jupyter-core!=5.0.*,>=4.12 in /usr/local/lib/python3.12/dist-packages (from nbformat->-r requirements.txt (line 13)) (5.9.1)\n",
            "Requirement already satisfied: traitlets>=5.1 in /usr/local/lib/python3.12/dist-packages (from nbformat->-r requirements.txt (line 13)) (5.7.1)\n",
            "Requirement already satisfied: altair!=5.4.0,!=5.4.1,<7,>=4.0 in /usr/local/lib/python3.12/dist-packages (from streamlit->-r requirements.txt (line 14)) (5.5.0)\n",
            "Requirement already satisfied: blinker<2,>=1.5.0 in /usr/local/lib/python3.12/dist-packages (from streamlit->-r requirements.txt (line 14)) (1.9.0)\n",
            "Requirement already satisfied: cachetools<7,>=4.0 in /usr/local/lib/python3.12/dist-packages (from streamlit->-r requirements.txt (line 14)) (6.2.2)\n",
            "Requirement already satisfied: click<9,>=7.0 in /usr/local/lib/python3.12/dist-packages (from streamlit->-r requirements.txt (line 14)) (8.3.1)\n",
            "Requirement already satisfied: protobuf<7,>=3.20 in /usr/local/lib/python3.12/dist-packages (from streamlit->-r requirements.txt (line 14)) (5.29.5)\n",
            "Requirement already satisfied: pyarrow>=7.0 in /usr/local/lib/python3.12/dist-packages (from streamlit->-r requirements.txt (line 14)) (18.1.0)\n",
            "Requirement already satisfied: tenacity<10,>=8.1.0 in /usr/local/lib/python3.12/dist-packages (from streamlit->-r requirements.txt (line 14)) (9.1.2)\n",
            "Requirement already satisfied: toml<2,>=0.10.1 in /usr/local/lib/python3.12/dist-packages (from streamlit->-r requirements.txt (line 14)) (0.10.2)\n",
            "Requirement already satisfied: watchdog<7,>=2.1.5 in /usr/local/lib/python3.12/dist-packages (from streamlit->-r requirements.txt (line 14)) (6.0.0)\n",
            "Requirement already satisfied: gitpython!=3.1.19,<4,>=3.0.7 in /usr/local/lib/python3.12/dist-packages (from streamlit->-r requirements.txt (line 14)) (3.1.45)\n",
            "Collecting pydeck<1,>=0.8.0b4 (from streamlit->-r requirements.txt (line 14))\n",
            "  Downloading pydeck-0.9.1-py2.py3-none-any.whl.metadata (4.1 kB)\n",
            "Requirement already satisfied: tornado!=6.5.0,<7,>=6.0.3 in /usr/local/lib/python3.12/dist-packages (from streamlit->-r requirements.txt (line 14)) (6.5.1)\n",
            "Requirement already satisfied: joblib>=1.2.0 in /usr/local/lib/python3.12/dist-packages (from scikit-learn->-r requirements.txt (line 17)) (1.5.2)\n",
            "Requirement already satisfied: threadpoolctl>=3.1.0 in /usr/local/lib/python3.12/dist-packages (from scikit-learn->-r requirements.txt (line 17)) (3.6.0)\n",
            "Requirement already satisfied: psutil in /usr/local/lib/python3.12/dist-packages (from accelerate->-r requirements.txt (line 18)) (5.9.5)\n",
            "Requirement already satisfied: narwhals>=1.14.2 in /usr/local/lib/python3.12/dist-packages (from altair!=5.4.0,!=5.4.1,<7,>=4.0->streamlit->-r requirements.txt (line 14)) (2.12.0)\n",
            "Requirement already satisfied: soupsieve>1.2 in /usr/local/lib/python3.12/dist-packages (from beautifulsoup4<5.0.0,>=4.9.1->deep-translator->-r requirements.txt (line 7)) (2.8)\n",
            "Requirement already satisfied: gitdb<5,>=4.0.1 in /usr/local/lib/python3.12/dist-packages (from gitpython!=3.1.19,<4,>=3.0.7->streamlit->-r requirements.txt (line 14)) (4.0.12)\n",
            "Requirement already satisfied: hf-xet<2.0.0,>=1.1.3 in /usr/local/lib/python3.12/dist-packages (from huggingface-hub<1.0,>=0.34.0->transformers->-r requirements.txt (line 4)) (1.2.0)\n",
            "Requirement already satisfied: attrs>=22.2.0 in /usr/local/lib/python3.12/dist-packages (from jsonschema>=2.6->nbformat->-r requirements.txt (line 13)) (25.4.0)\n",
            "Requirement already satisfied: jsonschema-specifications>=2023.03.6 in /usr/local/lib/python3.12/dist-packages (from jsonschema>=2.6->nbformat->-r requirements.txt (line 13)) (2025.9.1)\n",
            "Requirement already satisfied: referencing>=0.28.4 in /usr/local/lib/python3.12/dist-packages (from jsonschema>=2.6->nbformat->-r requirements.txt (line 13)) (0.37.0)\n",
            "Requirement already satisfied: rpds-py>=0.7.1 in /usr/local/lib/python3.12/dist-packages (from jsonschema>=2.6->nbformat->-r requirements.txt (line 13)) (0.29.0)\n",
            "Requirement already satisfied: platformdirs>=2.5 in /usr/local/lib/python3.12/dist-packages (from jupyter-core!=5.0.*,>=4.12->nbformat->-r requirements.txt (line 13)) (4.5.0)\n",
            "Requirement already satisfied: annotated-types>=0.6.0 in /usr/local/lib/python3.12/dist-packages (from pydantic!=1.8,!=1.8.1,<3.0.0,>=1.7.4->spacy->-r requirements.txt (line 12)) (0.7.0)\n",
            "Requirement already satisfied: pydantic-core==2.41.4 in /usr/local/lib/python3.12/dist-packages (from pydantic!=1.8,!=1.8.1,<3.0.0,>=1.7.4->spacy->-r requirements.txt (line 12)) (2.41.4)\n",
            "Requirement already satisfied: typing-inspection>=0.4.2 in /usr/local/lib/python3.12/dist-packages (from pydantic!=1.8,!=1.8.1,<3.0.0,>=1.7.4->spacy->-r requirements.txt (line 12)) (0.4.2)\n",
            "Requirement already satisfied: MarkupSafe>=2.0 in /usr/local/lib/python3.12/dist-packages (from jinja2->torch->-r requirements.txt (line 3)) (3.0.3)\n",
            "Requirement already satisfied: charset_normalizer<4,>=2 in /usr/local/lib/python3.12/dist-packages (from requests->transformers->-r requirements.txt (line 4)) (3.4.4)\n",
            "Requirement already satisfied: idna<4,>=2.5 in /usr/local/lib/python3.12/dist-packages (from requests->transformers->-r requirements.txt (line 4)) (3.11)\n",
            "Requirement already satisfied: urllib3<3,>=1.21.1 in /usr/local/lib/python3.12/dist-packages (from requests->transformers->-r requirements.txt (line 4)) (2.5.0)\n",
            "Requirement already satisfied: certifi>=2017.4.17 in /usr/local/lib/python3.12/dist-packages (from requests->transformers->-r requirements.txt (line 4)) (2025.11.12)\n",
            "Requirement already satisfied: mpmath<1.4,>=1.1.0 in /usr/local/lib/python3.12/dist-packages (from sympy>=1.13.3->torch->-r requirements.txt (line 3)) (1.3.0)\n",
            "Requirement already satisfied: blis<1.4.0,>=1.3.0 in /usr/local/lib/python3.12/dist-packages (from thinc<8.4.0,>=8.3.4->spacy->-r requirements.txt (line 12)) (1.3.3)\n",
            "Requirement already satisfied: confection<1.0.0,>=0.0.1 in /usr/local/lib/python3.12/dist-packages (from thinc<8.4.0,>=8.3.4->spacy->-r requirements.txt (line 12)) (0.1.5)\n",
            "Requirement already satisfied: cloudpathlib<1.0.0,>=0.7.0 in /usr/local/lib/python3.12/dist-packages (from weasel<0.5.0,>=0.4.2->spacy->-r requirements.txt (line 12)) (0.23.0)\n",
            "Requirement already satisfied: smart-open<8.0.0,>=5.2.1 in /usr/local/lib/python3.12/dist-packages (from weasel<0.5.0,>=0.4.2->spacy->-r requirements.txt (line 12)) (7.5.0)\n",
            "Requirement already satisfied: smmap<6,>=3.0.1 in /usr/local/lib/python3.12/dist-packages (from gitdb<5,>=4.0.1->gitpython!=3.1.19,<4,>=3.0.7->streamlit->-r requirements.txt (line 14)) (5.0.2)\n",
            "Requirement already satisfied: wrapt in /usr/local/lib/python3.12/dist-packages (from smart-open<8.0.0,>=5.2.1->weasel<0.5.0,>=0.4.2->spacy->-r requirements.txt (line 12)) (2.0.1)\n",
            "Downloading deep_translator-1.11.4-py3-none-any.whl (42 kB)\n",
            "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m42.3/42.3 kB\u001b[0m \u001b[31m3.9 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hDownloading streamlit-1.52.0-py3-none-any.whl (9.0 MB)\n",
            "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m9.0/9.0 MB\u001b[0m \u001b[31m132.8 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hDownloading pydeck-0.9.1-py2.py3-none-any.whl (6.9 MB)\n",
            "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m6.9/6.9 MB\u001b[0m \u001b[31m139.2 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hBuilding wheels for collected packages: langdetect\n",
            "  Building wheel for langdetect (setup.py) ... \u001b[?25l\u001b[?25hdone\n",
            "  Created wheel for langdetect: filename=langdetect-1.0.9-py3-none-any.whl size=993223 sha256=274a7b591cf7eb0cc90cd7c67622eacf055c67a956ae2d78cdbc97ee4e5fb25e\n",
            "  Stored in directory: /root/.cache/pip/wheels/c1/67/88/e844b5b022812e15a52e4eaa38a1e709e99f06f6639d7e3ba7\n",
            "Successfully built langdetect\n",
            "Installing collected packages: langdetect, pydeck, deep-translator, streamlit\n",
            "Successfully installed deep-translator-1.11.4 langdetect-1.0.9 pydeck-0.9.1 streamlit-1.52.0\n"
          ]
        }
      ],
      "source": [
        "# 2. Install Dependencies\n",
        "!pip install -r requirements.txt"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 3,
      "metadata": {
        "id": "We-35O_0pCtz",
        "outputId": "c3c9ebe4-efea-48b7-d53e-0b1cfc4b9925",
        "colab": {
          "base_uri": "https://localhost:8080/"
        }
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "2025-12-05 18:04:44.286939: E external/local_xla/xla/stream_executor/cuda/cuda_fft.cc:467] Unable to register cuFFT factory: Attempting to register factory for plugin cuFFT when one has already been registered\n",
            "WARNING: All log messages before absl::InitializeLog() is called are written to STDERR\n",
            "E0000 00:00:1764957884.307460    1077 cuda_dnn.cc:8579] Unable to register cuDNN factory: Attempting to register factory for plugin cuDNN when one has already been registered\n",
            "E0000 00:00:1764957884.313635    1077 cuda_blas.cc:1407] Unable to register cuBLAS factory: Attempting to register factory for plugin cuBLAS when one has already been registered\n",
            "W0000 00:00:1764957884.329782    1077 computation_placer.cc:177] computation placer already registered. Please check linkage and avoid linking the same target more than once.\n",
            "W0000 00:00:1764957884.329811    1077 computation_placer.cc:177] computation placer already registered. Please check linkage and avoid linking the same target more than once.\n",
            "W0000 00:00:1764957884.329816    1077 computation_placer.cc:177] computation placer already registered. Please check linkage and avoid linking the same target more than once.\n",
            "W0000 00:00:1764957884.329819    1077 computation_placer.cc:177] computation placer already registered. Please check linkage and avoid linking the same target more than once.\n",
            "2025-12-05 18:04:44.334557: I tensorflow/core/platform/cpu_feature_guard.cc:210] This TensorFlow binary is optimized to use available CPU instructions in performance-critical operations.\n",
            "To enable the following instructions: AVX2 AVX512F FMA, in other operations, rebuild TensorFlow with the appropriate compiler flags.\n",
            "tokenizer_config.json: 100% 52.0/52.0 [00:00<00:00, 471kB/s]\n",
            "config.json: 100% 578/578 [00:00<00:00, 5.53MB/s]\n",
            "spm.model: 100% 2.46M/2.46M [00:01<00:00, 2.03MB/s]\n",
            "/usr/local/lib/python3.12/dist-packages/transformers/convert_slow_tokenizer.py:566: UserWarning: The sentencepiece tokenizer that you are converting to a fast tokenizer uses the byte fallback option which is not implemented in the fast tokenizers. In practice this means that the fast version of the tokenizer can produce unknown tokens whereas the sentencepiece version would have converted these unknown tokens into a sequence of byte tokens matching the original piece of text.\n",
            "  warnings.warn(\n",
            "pytorch_model.bin: 100% 286M/286M [00:03<00:00, 82.8MB/s]\n",
            "Some weights of DebertaV2ForSequenceClassification were not initialized from the model checkpoint at microsoft/deberta-v3-small and are newly initialized: ['classifier.bias', 'classifier.weight', 'pooler.dense.bias', 'pooler.dense.weight']\n",
            "You should probably TRAIN this model on a down-stream task to be able to use it for predictions and inference.\n",
            "  0% 0/831 [00:00<?, ?it/s]\n",
            "  0% 2/831 [00:01<11:49,  1.17it/s]\n",
            "  0% 3/831 [00:02<07:45,  1.78it/s]\n",
            "  0% 4/831 [00:02<05:51,  2.36it/s]\n",
            "  1% 6/831 [00:02<04:11,  3.28it/s]\n",
            "model.safetensors:  15% 41.8M/286M [00:02<00:07, 33.5MB/s]\u001b[A\n",
            "  1% 8/831 [00:03<03:32,  3.88it/s]\n",
            "                                    \n",
            "\u001b[A{'loss': 1.1044, 'grad_norm': 6.448355197906494, 'learning_rate': 9e-07, 'epoch': 0.04}\n",
            "  1% 10/831 [00:03<03:13,  4.24it/s]\n",
            "  1% 12/831 [00:04<03:06,  4.40it/s]\n",
            "  2% 14/831 [00:04<03:02,  4.47it/s]\n",
            "model.safetensors: 100% 286M/286M [00:03<00:00, 71.8MB/s]\n",
            "{'loss': 1.0956, 'grad_norm': 6.323613166809082, 'learning_rate': 1.9e-06, 'epoch': 0.07}\n",
            "{'loss': 1.0829, 'grad_norm': 6.156243324279785, 'learning_rate': 2.9e-06, 'epoch': 0.11}\n",
            "{'loss': 1.0468, 'grad_norm': 4.686546802520752, 'learning_rate': 3.9e-06, 'epoch': 0.14}\n",
            "{'loss': 1.0257, 'grad_norm': 8.023231506347656, 'learning_rate': 4.9000000000000005e-06, 'epoch': 0.18}\n",
            "{'loss': 0.9896, 'grad_norm': 6.0239386558532715, 'learning_rate': 5.9e-06, 'epoch': 0.22}\n",
            "{'loss': 0.9272, 'grad_norm': 2.242863178253174, 'learning_rate': 6.900000000000001e-06, 'epoch': 0.25}\n",
            "{'loss': 0.8266, 'grad_norm': 1.8122488260269165, 'learning_rate': 7.9e-06, 'epoch': 0.29}\n",
            "{'loss': 0.862, 'grad_norm': 1.9951661825180054, 'learning_rate': 8.9e-06, 'epoch': 0.32}\n",
            "{'loss': 0.6936, 'grad_norm': 2.878103733062744, 'learning_rate': 9.900000000000002e-06, 'epoch': 0.36}\n",
            "{'loss': 0.6102, 'grad_norm': 3.081176996231079, 'learning_rate': 1.09e-05, 'epoch': 0.4}\n",
            "{'loss': 0.6232, 'grad_norm': 5.874629497528076, 'learning_rate': 1.19e-05, 'epoch': 0.43}\n",
            "{'loss': 0.6155, 'grad_norm': 5.276557445526123, 'learning_rate': 1.29e-05, 'epoch': 0.47}\n",
            "{'loss': 0.5335, 'grad_norm': 3.19225811958313, 'learning_rate': 1.3900000000000002e-05, 'epoch': 0.51}\n",
            "{'loss': 0.4685, 'grad_norm': 5.204461097717285, 'learning_rate': 1.49e-05, 'epoch': 0.54}\n",
            "{'loss': 0.5303, 'grad_norm': 3.8132994174957275, 'learning_rate': 1.59e-05, 'epoch': 0.58}\n",
            "{'loss': 0.5304, 'grad_norm': 9.558765411376953, 'learning_rate': 1.69e-05, 'epoch': 0.61}\n",
            "{'loss': 0.4965, 'grad_norm': 11.519408226013184, 'learning_rate': 1.79e-05, 'epoch': 0.65}\n",
            "{'loss': 0.3671, 'grad_norm': 5.2018938064575195, 'learning_rate': 1.8900000000000002e-05, 'epoch': 0.69}\n",
            "{'loss': 0.5133, 'grad_norm': 3.940516710281372, 'learning_rate': 1.9900000000000003e-05, 'epoch': 0.72}\n",
            "{'loss': 0.4693, 'grad_norm': 3.472507953643799, 'learning_rate': 2.09e-05, 'epoch': 0.76}\n",
            "{'loss': 0.4411, 'grad_norm': 0.37128111720085144, 'learning_rate': 2.19e-05, 'epoch': 0.79}\n",
            "{'loss': 0.3566, 'grad_norm': 2.6660983562469482, 'learning_rate': 2.29e-05, 'epoch': 0.83}\n",
            "{'loss': 0.5109, 'grad_norm': 5.346867084503174, 'learning_rate': 2.39e-05, 'epoch': 0.87}\n",
            "{'loss': 0.4227, 'grad_norm': 12.05576229095459, 'learning_rate': 2.4900000000000002e-05, 'epoch': 0.9}\n",
            "{'loss': 0.5007, 'grad_norm': 4.111695766448975, 'learning_rate': 2.5900000000000003e-05, 'epoch': 0.94}\n",
            "{'loss': 0.4447, 'grad_norm': 4.799881935119629, 'learning_rate': 2.6900000000000003e-05, 'epoch': 0.97}\n",
            " 33% 277/831 [01:01<01:50,  5.01it/s]\n",
            "  0% 0/70 [00:00<?, ?it/s]\u001b[A\n",
            "  4% 3/70 [00:00<00:02, 22.50it/s]\u001b[A\n",
            "  9% 6/70 [00:00<00:03, 17.53it/s]\u001b[A\n",
            " 11% 8/70 [00:00<00:03, 16.61it/s]\u001b[A\n",
            " 14% 10/70 [00:00<00:03, 16.09it/s]\u001b[A\n",
            " 17% 12/70 [00:00<00:03, 15.66it/s]\u001b[A\n",
            " 20% 14/70 [00:00<00:03, 15.41it/s]\u001b[A\n",
            " 23% 16/70 [00:00<00:03, 15.37it/s]\u001b[A\n",
            " 26% 18/70 [00:01<00:03, 15.27it/s]\u001b[A\n",
            " 29% 20/70 [00:01<00:03, 15.24it/s]\u001b[A\n",
            " 31% 22/70 [00:01<00:03, 15.21it/s]\u001b[A\n",
            " 34% 24/70 [00:01<00:03, 15.18it/s]\u001b[A\n",
            " 37% 26/70 [00:01<00:02, 15.16it/s]\u001b[A\n",
            " 40% 28/70 [00:01<00:02, 15.12it/s]\u001b[A\n",
            " 43% 30/70 [00:01<00:02, 15.12it/s]\u001b[A\n",
            " 46% 32/70 [00:02<00:02, 15.07it/s]\u001b[A\n",
            " 49% 34/70 [00:02<00:02, 15.10it/s]\u001b[A\n",
            " 51% 36/70 [00:02<00:02, 15.04it/s]\u001b[A\n",
            " 54% 38/70 [00:02<00:02, 15.08it/s]\u001b[A\n",
            " 57% 40/70 [00:02<00:01, 15.08it/s]\u001b[A\n",
            " 60% 42/70 [00:02<00:01, 15.19it/s]\u001b[A\n",
            " 63% 44/70 [00:02<00:01, 15.13it/s]\u001b[A\n",
            " 66% 46/70 [00:02<00:01, 15.11it/s]\u001b[A\n",
            " 69% 48/70 [00:03<00:01, 15.10it/s]\u001b[A\n",
            " 71% 50/70 [00:03<00:01, 15.06it/s]\u001b[A\n",
            " 74% 52/70 [00:03<00:01, 15.12it/s]\u001b[A\n",
            " 77% 54/70 [00:03<00:01, 15.13it/s]\u001b[A\n",
            " 80% 56/70 [00:03<00:00, 15.17it/s]\u001b[A\n",
            " 83% 58/70 [00:03<00:00, 15.17it/s]\u001b[A\n",
            " 86% 60/70 [00:03<00:00, 15.20it/s]\u001b[A\n",
            " 89% 62/70 [00:04<00:00, 15.16it/s]\u001b[A\n",
            " 91% 64/70 [00:04<00:00, 15.18it/s]\u001b[A\n",
            " 94% 66/70 [00:04<00:00, 15.14it/s]\u001b[A\n",
            "                                     \n",
            "\u001b[A{'eval_loss': 0.40446656942367554, 'eval_accuracy': 0.8256549232158988, 'eval_f1': 0.8166650892815243, 'eval_precision': 0.8161296258520601, 'eval_recall': 0.8256549232158988, 'eval_runtime': 4.62, 'eval_samples_per_second': 239.612, 'eval_steps_per_second': 15.152, 'epoch': 1.0}\n",
            " 33% 277/831 [01:06<01:50,  5.01it/s]\n",
            "100% 70/70 [00:04<00:00, 15.14it/s]\u001b[A\n",
            "{'loss': 0.3618, 'grad_norm': 1.4059772491455078, 'learning_rate': 2.7900000000000004e-05, 'epoch': 1.01}\n",
            "{'loss': 0.3463, 'grad_norm': 15.821900367736816, 'learning_rate': 2.8899999999999998e-05, 'epoch': 1.05}\n",
            "{'loss': 0.2614, 'grad_norm': 6.413037300109863, 'learning_rate': 2.9900000000000002e-05, 'epoch': 1.08}\n",
            "{'loss': 0.1727, 'grad_norm': 6.152459621429443, 'learning_rate': 3.09e-05, 'epoch': 1.12}\n",
            "{'loss': 0.5369, 'grad_norm': 5.117323398590088, 'learning_rate': 3.19e-05, 'epoch': 1.16}\n",
            "{'loss': 0.4719, 'grad_norm': 2.3903863430023193, 'learning_rate': 3.29e-05, 'epoch': 1.19}\n",
            "{'loss': 0.3751, 'grad_norm': 3.8443782329559326, 'learning_rate': 3.3900000000000004e-05, 'epoch': 1.23}\n",
            "{'loss': 0.5034, 'grad_norm': 5.603711128234863, 'learning_rate': 3.49e-05, 'epoch': 1.26}\n",
            "{'loss': 0.4335, 'grad_norm': 4.282230377197266, 'learning_rate': 3.59e-05, 'epoch': 1.3}\n",
            "{'loss': 0.375, 'grad_norm': 4.194453239440918, 'learning_rate': 3.69e-05, 'epoch': 1.34}\n",
            "{'loss': 0.3391, 'grad_norm': 8.707969665527344, 'learning_rate': 3.79e-05, 'epoch': 1.37}\n",
            "{'loss': 0.3252, 'grad_norm': 3.046549081802368, 'learning_rate': 3.8900000000000004e-05, 'epoch': 1.41}\n",
            "{'loss': 0.3296, 'grad_norm': 2.4174447059631348, 'learning_rate': 3.99e-05, 'epoch': 1.44}\n",
            "{'loss': 0.3894, 'grad_norm': 6.790830135345459, 'learning_rate': 4.09e-05, 'epoch': 1.48}\n",
            "{'loss': 0.3155, 'grad_norm': 11.64986515045166, 'learning_rate': 4.19e-05, 'epoch': 1.52}\n",
            "{'loss': 0.405, 'grad_norm': 6.840329647064209, 'learning_rate': 4.29e-05, 'epoch': 1.55}\n",
            "{'loss': 0.355, 'grad_norm': 19.664369583129883, 'learning_rate': 4.39e-05, 'epoch': 1.59}\n",
            "{'loss': 0.3412, 'grad_norm': 3.647279977798462, 'learning_rate': 4.49e-05, 'epoch': 1.62}\n",
            "{'loss': 0.2908, 'grad_norm': 4.057802200317383, 'learning_rate': 4.5900000000000004e-05, 'epoch': 1.66}\n",
            "{'loss': 0.4314, 'grad_norm': 5.169135093688965, 'learning_rate': 4.69e-05, 'epoch': 1.7}\n",
            "{'loss': 0.3843, 'grad_norm': 5.839360237121582, 'learning_rate': 4.79e-05, 'epoch': 1.73}\n",
            "{'loss': 0.4109, 'grad_norm': 4.45211124420166, 'learning_rate': 4.89e-05, 'epoch': 1.77}\n",
            "{'loss': 0.2164, 'grad_norm': 4.893099784851074, 'learning_rate': 4.99e-05, 'epoch': 1.81}\n",
            "{'loss': 0.2783, 'grad_norm': 10.628369331359863, 'learning_rate': 4.86404833836858e-05, 'epoch': 1.84}\n",
            "{'loss': 0.376, 'grad_norm': 0.4661623239517212, 'learning_rate': 4.712990936555892e-05, 'epoch': 1.88}\n",
            "{'loss': 0.2141, 'grad_norm': 4.77915096282959, 'learning_rate': 4.5619335347432025e-05, 'epoch': 1.91}\n",
            "{'loss': 0.4288, 'grad_norm': 24.49591827392578, 'learning_rate': 4.410876132930514e-05, 'epoch': 1.95}\n",
            "{'loss': 0.3435, 'grad_norm': 3.5941319465637207, 'learning_rate': 4.259818731117825e-05, 'epoch': 1.99}\n",
            " 67% 554/831 [02:27<00:56,  4.93it/s]\n",
            "  0% 0/70 [00:00<?, ?it/s]\u001b[A\n",
            "  4% 3/70 [00:00<00:03, 21.65it/s]\u001b[A\n",
            "  9% 6/70 [00:00<00:03, 16.93it/s]\u001b[A\n",
            " 11% 8/70 [00:00<00:03, 16.13it/s]\u001b[A\n",
            " 14% 10/70 [00:00<00:03, 15.66it/s]\u001b[A\n",
            " 17% 12/70 [00:00<00:03, 15.25it/s]\u001b[A\n",
            " 20% 14/70 [00:00<00:03, 15.12it/s]\u001b[A\n",
            " 23% 16/70 [00:01<00:03, 15.02it/s]\u001b[A\n",
            " 26% 18/70 [00:01<00:03, 14.92it/s]\u001b[A\n",
            " 29% 20/70 [00:01<00:03, 14.93it/s]\u001b[A\n",
            " 31% 22/70 [00:01<00:03, 14.81it/s]\u001b[A\n",
            " 34% 24/70 [00:01<00:03, 14.83it/s]\u001b[A\n",
            " 37% 26/70 [00:01<00:02, 14.79it/s]\u001b[A\n",
            " 40% 28/70 [00:01<00:02, 14.77it/s]\u001b[A\n",
            " 43% 30/70 [00:01<00:02, 14.71it/s]\u001b[A\n",
            " 46% 32/70 [00:02<00:02, 14.70it/s]\u001b[A\n",
            " 49% 34/70 [00:02<00:02, 14.79it/s]\u001b[A\n",
            " 51% 36/70 [00:02<00:02, 14.76it/s]\u001b[A\n",
            " 54% 38/70 [00:02<00:02, 14.79it/s]\u001b[A\n",
            " 57% 40/70 [00:02<00:02, 14.82it/s]\u001b[A\n",
            " 60% 42/70 [00:02<00:01, 14.75it/s]\u001b[A\n",
            " 63% 44/70 [00:02<00:01, 14.75it/s]\u001b[A\n",
            " 66% 46/70 [00:03<00:01, 14.76it/s]\u001b[A\n",
            " 69% 48/70 [00:03<00:01, 14.73it/s]\u001b[A\n",
            " 71% 50/70 [00:03<00:01, 14.64it/s]\u001b[A\n",
            " 74% 52/70 [00:03<00:01, 14.69it/s]\u001b[A\n",
            " 77% 54/70 [00:03<00:01, 14.75it/s]\u001b[A\n",
            " 80% 56/70 [00:03<00:00, 14.67it/s]\u001b[A\n",
            " 83% 58/70 [00:03<00:00, 14.60it/s]\u001b[A\n",
            " 86% 60/70 [00:04<00:00, 14.69it/s]\u001b[A\n",
            " 89% 62/70 [00:04<00:00, 14.76it/s]\u001b[A\n",
            " 91% 64/70 [00:04<00:00, 14.70it/s]\u001b[A\n",
            " 94% 66/70 [00:04<00:00, 14.72it/s]\u001b[A\n",
            "                                     \n",
            "\u001b[A{'eval_loss': 0.3383559286594391, 'eval_accuracy': 0.8762420957542909, 'eval_f1': 0.8727367041205195, 'eval_precision': 0.8725039531655954, 'eval_recall': 0.8762420957542909, 'eval_runtime': 4.7356, 'eval_samples_per_second': 233.762, 'eval_steps_per_second': 14.782, 'epoch': 2.0}\n",
            " 67% 554/831 [02:31<00:56,  4.93it/s]\n",
            "100% 70/70 [00:04<00:00, 14.78it/s]\u001b[A\n",
            "{'loss': 0.3095, 'grad_norm': 3.492114782333374, 'learning_rate': 4.108761329305136e-05, 'epoch': 2.02}\n",
            "{'loss': 0.2386, 'grad_norm': 4.305115699768066, 'learning_rate': 3.957703927492447e-05, 'epoch': 2.06}\n",
            "{'loss': 0.2408, 'grad_norm': 14.89442253112793, 'learning_rate': 3.8066465256797584e-05, 'epoch': 2.09}\n",
            "{'loss': 0.142, 'grad_norm': 5.448061466217041, 'learning_rate': 3.65558912386707e-05, 'epoch': 2.13}\n",
            "{'loss': 0.3166, 'grad_norm': 11.584749221801758, 'learning_rate': 3.504531722054381e-05, 'epoch': 2.17}\n",
            "{'loss': 0.4246, 'grad_norm': 3.853339672088623, 'learning_rate': 3.353474320241692e-05, 'epoch': 2.2}\n",
            "{'loss': 0.2223, 'grad_norm': 20.925634384155273, 'learning_rate': 3.202416918429003e-05, 'epoch': 2.24}\n",
            "{'loss': 0.4025, 'grad_norm': 4.327612400054932, 'learning_rate': 3.0513595166163146e-05, 'epoch': 2.27}\n",
            "{'loss': 0.1294, 'grad_norm': 0.9201599955558777, 'learning_rate': 2.9003021148036257e-05, 'epoch': 2.31}\n",
            "{'loss': 0.2955, 'grad_norm': 10.962634086608887, 'learning_rate': 2.7492447129909365e-05, 'epoch': 2.35}\n",
            "{'loss': 0.2582, 'grad_norm': 10.655611038208008, 'learning_rate': 2.598187311178248e-05, 'epoch': 2.38}\n",
            "{'loss': 0.1661, 'grad_norm': 2.6345298290252686, 'learning_rate': 2.447129909365559e-05, 'epoch': 2.42}\n",
            "{'loss': 0.2102, 'grad_norm': 9.176337242126465, 'learning_rate': 2.2960725075528702e-05, 'epoch': 2.45}\n",
            "{'loss': 0.1468, 'grad_norm': 6.379567623138428, 'learning_rate': 2.1450151057401813e-05, 'epoch': 2.49}\n",
            "{'loss': 0.2035, 'grad_norm': 3.3292248249053955, 'learning_rate': 1.9939577039274927e-05, 'epoch': 2.53}\n",
            "{'loss': 0.1815, 'grad_norm': 0.9858773350715637, 'learning_rate': 1.8429003021148035e-05, 'epoch': 2.56}\n",
            "{'loss': 0.2587, 'grad_norm': 7.969592094421387, 'learning_rate': 1.691842900302115e-05, 'epoch': 2.6}\n",
            "{'loss': 0.1923, 'grad_norm': 1.1007167100906372, 'learning_rate': 1.540785498489426e-05, 'epoch': 2.64}\n",
            "{'loss': 0.2423, 'grad_norm': 3.2938761711120605, 'learning_rate': 1.3897280966767373e-05, 'epoch': 2.67}\n",
            "{'loss': 0.198, 'grad_norm': 6.943179130554199, 'learning_rate': 1.2386706948640483e-05, 'epoch': 2.71}\n",
            "{'loss': 0.1574, 'grad_norm': 3.3148932456970215, 'learning_rate': 1.0876132930513596e-05, 'epoch': 2.74}\n",
            "{'loss': 0.1086, 'grad_norm': 8.52264404296875, 'learning_rate': 9.365558912386707e-06, 'epoch': 2.78}\n",
            "{'loss': 0.1864, 'grad_norm': 4.156482696533203, 'learning_rate': 7.85498489425982e-06, 'epoch': 2.82}\n",
            "{'loss': 0.1478, 'grad_norm': 4.926689624786377, 'learning_rate': 6.344410876132931e-06, 'epoch': 2.85}\n",
            "{'loss': 0.134, 'grad_norm': 4.4388508796691895, 'learning_rate': 4.833836858006043e-06, 'epoch': 2.89}\n",
            "{'loss': 0.1942, 'grad_norm': 4.67740535736084, 'learning_rate': 3.323262839879154e-06, 'epoch': 2.92}\n",
            "{'loss': 0.1656, 'grad_norm': 7.186710834503174, 'learning_rate': 1.812688821752266e-06, 'epoch': 2.96}\n",
            "{'loss': 0.0536, 'grad_norm': 1.6904734373092651, 'learning_rate': 3.0211480362537766e-07, 'epoch': 3.0}\n",
            "100% 831/831 [03:47<00:00,  4.83it/s]\n",
            "  0% 0/70 [00:00<?, ?it/s]\u001b[A\n",
            "  4% 3/70 [00:00<00:03, 21.71it/s]\u001b[A\n",
            "  9% 6/70 [00:00<00:03, 16.73it/s]\u001b[A\n",
            " 11% 8/70 [00:00<00:03, 15.91it/s]\u001b[A\n",
            " 14% 10/70 [00:00<00:03, 15.35it/s]\u001b[A\n",
            " 17% 12/70 [00:00<00:03, 14.99it/s]\u001b[A\n",
            " 20% 14/70 [00:00<00:03, 14.81it/s]\u001b[A\n",
            " 23% 16/70 [00:01<00:03, 14.79it/s]\u001b[A\n",
            " 26% 18/70 [00:01<00:03, 14.75it/s]\u001b[A\n",
            " 29% 20/70 [00:01<00:03, 14.69it/s]\u001b[A\n",
            " 31% 22/70 [00:01<00:03, 14.61it/s]\u001b[A\n",
            " 34% 24/70 [00:01<00:03, 14.55it/s]\u001b[A\n",
            " 37% 26/70 [00:01<00:03, 14.56it/s]\u001b[A\n",
            " 40% 28/70 [00:01<00:02, 14.59it/s]\u001b[A\n",
            " 43% 30/70 [00:01<00:02, 14.59it/s]\u001b[A\n",
            " 46% 32/70 [00:02<00:02, 14.58it/s]\u001b[A\n",
            " 49% 34/70 [00:02<00:02, 14.58it/s]\u001b[A\n",
            " 51% 36/70 [00:02<00:02, 14.50it/s]\u001b[A\n",
            " 54% 38/70 [00:02<00:02, 14.60it/s]\u001b[A\n",
            " 57% 40/70 [00:02<00:02, 14.59it/s]\u001b[A\n",
            " 60% 42/70 [00:02<00:01, 14.55it/s]\u001b[A\n",
            " 63% 44/70 [00:02<00:01, 14.58it/s]\u001b[A\n",
            " 66% 46/70 [00:03<00:01, 14.61it/s]\u001b[A\n",
            " 69% 48/70 [00:03<00:01, 14.58it/s]\u001b[A\n",
            " 71% 50/70 [00:03<00:01, 14.53it/s]\u001b[A\n",
            " 74% 52/70 [00:03<00:01, 14.50it/s]\u001b[A\n",
            " 77% 54/70 [00:03<00:01, 14.55it/s]\u001b[A\n",
            " 80% 56/70 [00:03<00:00, 14.61it/s]\u001b[A\n",
            " 83% 58/70 [00:03<00:00, 14.54it/s]\u001b[A\n",
            " 86% 60/70 [00:04<00:00, 14.52it/s]\u001b[A\n",
            " 89% 62/70 [00:04<00:00, 14.47it/s]\u001b[A\n",
            " 91% 64/70 [00:04<00:00, 14.44it/s]\u001b[A\n",
            " 94% 66/70 [00:04<00:00, 14.44it/s]\u001b[A\n",
            "                                     \n",
            "\u001b[A{'eval_loss': 0.290282279253006, 'eval_accuracy': 0.9150858175248419, 'eval_f1': 0.9158294767903151, 'eval_precision': 0.9167814122337671, 'eval_recall': 0.9150858175248419, 'eval_runtime': 4.8018, 'eval_samples_per_second': 230.538, 'eval_steps_per_second': 14.578, 'epoch': 3.0}\n",
            "100% 831/831 [03:52<00:00,  4.83it/s]\n",
            "100% 70/70 [00:04<00:00, 14.39it/s]\u001b[A\n",
            "{'train_runtime': 261.3981, 'train_samples_per_second': 50.796, 'train_steps_per_second': 3.179, 'train_loss': 0.41016016575977404, 'epoch': 3.0}\n",
            "100% 831/831 [04:21<00:00,  3.18it/s]\n",
            "100% 70/70 [00:04<00:00, 15.03it/s]\n"
          ]
        }
      ],
      "source": [
        "# 3. Run the Training Script\n",
        "# This uses the 'absa_training_dataset.csv' from your repository\n",
        "!python train_absa_model.py"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 4,
      "metadata": {
        "id": "--RXU62dpCtz",
        "outputId": "14bc1204-2754-4059-b1b3-e55ea3c7b470",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 446
        }
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "  adding: outputs/fine_tuned_absa_model/ (stored 0%)\n",
            "  adding: outputs/fine_tuned_absa_model/checkpoint-554/ (stored 0%)\n",
            "  adding: outputs/fine_tuned_absa_model/checkpoint-554/config.json (deflated 55%)\n",
            "  adding: outputs/fine_tuned_absa_model/checkpoint-554/trainer_state.json (deflated 77%)\n",
            "  adding: outputs/fine_tuned_absa_model/checkpoint-554/scheduler.pt (deflated 61%)\n",
            "  adding: outputs/fine_tuned_absa_model/checkpoint-554/rng_state.pth (deflated 26%)\n",
            "  adding: outputs/fine_tuned_absa_model/checkpoint-554/model.safetensors (deflated 26%)\n",
            "  adding: outputs/fine_tuned_absa_model/checkpoint-554/optimizer.pt (deflated 69%)\n",
            "  adding: outputs/fine_tuned_absa_model/checkpoint-554/training_args.bin (deflated 54%)\n",
            "  adding: outputs/fine_tuned_absa_model/config.json (deflated 55%)\n",
            "  adding: outputs/fine_tuned_absa_model/special_tokens_map.json (deflated 50%)\n",
            "  adding: outputs/fine_tuned_absa_model/tokenizer.json (deflated 77%)\n",
            "  adding: outputs/fine_tuned_absa_model/added_tokens.json (stored 0%)\n",
            "  adding: outputs/fine_tuned_absa_model/checkpoint-831/ (stored 0%)\n",
            "  adding: outputs/fine_tuned_absa_model/checkpoint-831/config.json (deflated 55%)\n",
            "  adding: outputs/fine_tuned_absa_model/checkpoint-831/trainer_state.json (deflated 78%)\n",
            "  adding: outputs/fine_tuned_absa_model/checkpoint-831/scheduler.pt (deflated 62%)\n",
            "  adding: outputs/fine_tuned_absa_model/checkpoint-831/rng_state.pth (deflated 26%)\n",
            "  adding: outputs/fine_tuned_absa_model/checkpoint-831/model.safetensors (deflated 26%)\n",
            "  adding: outputs/fine_tuned_absa_model/checkpoint-831/optimizer.pt (deflated 69%)\n",
            "  adding: outputs/fine_tuned_absa_model/checkpoint-831/training_args.bin (deflated 54%)\n",
            "  adding: outputs/fine_tuned_absa_model/model.safetensors (deflated 26%)\n",
            "  adding: outputs/fine_tuned_absa_model/tokenizer_config.json (deflated 73%)\n",
            "  adding: outputs/fine_tuned_absa_model/spm.model (deflated 50%)\n"
          ]
        },
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "<IPython.core.display.Javascript object>"
            ],
            "application/javascript": [
              "\n",
              "    async function download(id, filename, size) {\n",
              "      if (!google.colab.kernel.accessAllowed) {\n",
              "        return;\n",
              "      }\n",
              "      const div = document.createElement('div');\n",
              "      const label = document.createElement('label');\n",
              "      label.textContent = `Downloading \"${filename}\": `;\n",
              "      div.appendChild(label);\n",
              "      const progress = document.createElement('progress');\n",
              "      progress.max = size;\n",
              "      div.appendChild(progress);\n",
              "      document.body.appendChild(div);\n",
              "\n",
              "      const buffers = [];\n",
              "      let downloaded = 0;\n",
              "\n",
              "      const channel = await google.colab.kernel.comms.open(id);\n",
              "      // Send a message to notify the kernel that we're ready.\n",
              "      channel.send({})\n",
              "\n",
              "      for await (const message of channel.messages) {\n",
              "        // Send a message to notify the kernel that we're ready.\n",
              "        channel.send({})\n",
              "        if (message.buffers) {\n",
              "          for (const buffer of message.buffers) {\n",
              "            buffers.push(buffer);\n",
              "            downloaded += buffer.byteLength;\n",
              "            progress.value = downloaded;\n",
              "          }\n",
              "        }\n",
              "      }\n",
              "      const blob = new Blob(buffers, {type: 'application/binary'});\n",
              "      const a = document.createElement('a');\n",
              "      a.href = window.URL.createObjectURL(blob);\n",
              "      a.download = filename;\n",
              "      div.appendChild(a);\n",
              "      a.click();\n",
              "      div.remove();\n",
              "    }\n",
              "  "
            ]
          },
          "metadata": {}
        },
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "<IPython.core.display.Javascript object>"
            ],
            "application/javascript": [
              "download(\"download_adcb2718-7fea-4c16-aef7-dc179c14e723\", \"fine_tuned_model.zip\", 1957257229)"
            ]
          },
          "metadata": {}
        }
      ],
      "source": [
        "# 4. (Optional) Zip and Download the Trained Model\n",
        "!zip -r fine_tuned_model.zip outputs/fine_tuned_absa_model\n",
        "\n",
        "from google.colab import files\n",
        "files.download('fine_tuned_model.zip')"
      ]
    }
  ],
  "metadata": {
    "kernelspec": {
      "display_name": "Python 3",
      "name": "python3"
    },
    "language_info": {
      "codemirror_mode": {
        "name": "ipython",
        "version": 3
      },
      "file_extension": ".py",
      "mimetype": "text/x-python",
      "name": "python",
      "nbconvert_exporter": "python",
      "pygments_lexer": "ipython3",
      "version": "3.8.5"
    },
    "colab": {
      "provenance": [],
      "gpuType": "T4",
      "include_colab_link": true
    },
    "accelerator": "GPU"
  },
  "nbformat": 4,
  "nbformat_minor": 0
}