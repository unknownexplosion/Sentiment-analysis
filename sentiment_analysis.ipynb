{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "3868f12c",
   "metadata": {},
   "source": [
    "# Sentiment Analysis & Feedback System\n",
    "\n",
    "This notebook implements a complete sentiment analysis pipeline for customer reviews.\n",
    "It performs:\n",
    "1. Data Loading & Cleaning\n",
    "2. Language Translation\n",
    "3. Duplicate Removal\n",
    "4. Sentiment Analysis (BERT)\n",
    "5. Aggregation & Reporting\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a74e047d",
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import os\n",
    "import sys\n",
    "import matplotlib.pyplot as plt\n",
    "from IPython.display import display, Image\n",
    "\n",
    "# Add current directory to path to import pipeline\n",
    "sys.path.append(os.getcwd())\n",
    "\n",
    "# Import functions from our pipeline script\n",
    "from sentiment_pipeline import (\n",
    "    load_data, preprocess_reviews, translate_and_clean, \n",
    "    handle_duplicates, analyze_sentiment, generate_absa_dataset, aggregate_model_stats, \n",
    "    generate_feedback_report, plot_results\n",
    ")\n",
    "\n",
    "# %matplotlib inline\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b4001dd0",
   "metadata": {},
   "outputs": [],
   "source": [
    "# 1. Load Data\n",
    "dataset_path = 'final_dataset.csv'\n",
    "df = load_data(dataset_path)\n",
    "display(df.head())\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "892454af",
   "metadata": {},
   "outputs": [],
   "source": [
    "# 2. Preprocess (Clean & Filter)\n",
    "df = preprocess_reviews(df)\n",
    "print(f\"Rows after cleaning: {len(df)}\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "3073a397",
   "metadata": {},
   "outputs": [],
   "source": [
    "# 3. Translate & Re-clean\n",
    "# This step might take time if using actual translation API\n",
    "df = translate_and_clean(df)\n",
    "display(df[['original_review', 'final_review']].head())\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "57515f9c",
   "metadata": {},
   "outputs": [],
   "source": [
    "# 4. Handle Duplicates\n",
    "df = handle_duplicates(df)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b6ce6222",
   "metadata": {},
   "outputs": [],
   "source": [
    "# 5. Sentiment Analysis\n",
    "df, sentiment_pipe = analyze_sentiment(df)\n",
    "display(df[['model', 'final_review', 'sentiment_label', 'sentiment_score']].head())\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "0fedbd41",
   "metadata": {},
   "outputs": [],
   "source": [
    "# 6. ABSA Dataset Generation\n",
    "absa_df = generate_absa_dataset(df, sentiment_pipe)\n",
    "if not absa_df.empty:\n",
    "    display(absa_df.head())\n",
    "else:\n",
    "    print(\"No ABSA data generated (Spacy missing or no aspects found).\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "4a4e0f8b",
   "metadata": {},
   "outputs": [],
   "source": [
    "# 6. Aggregate Stats\n",
    "stats_df = aggregate_model_stats(df)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "02a88d0d",
   "metadata": {},
   "outputs": [],
   "source": [
    "# 7. Generate Feedback Report\n",
    "feedback_df = generate_feedback_report(stats_df)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e496b75e",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Display Summary Tables (Requirement 7)\n",
    "\n",
    "print(\"=== Model Summary ===\")\n",
    "display(stats_df.head(10))\n",
    "\n",
    "print(\"\\n=== Feedback Report ===\")\n",
    "display(feedback_df.head(10))\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "dbfb4630",
   "metadata": {},
   "outputs": [],
   "source": [
    "# 8. Save Outputs\n",
    "output_dir = 'outputs'\n",
    "plots_dir = os.path.join(output_dir, 'plots')\n",
    "os.makedirs(output_dir, exist_ok=True)\n",
    "\n",
    "df.to_csv(os.path.join(output_dir, 'sentiment_output.csv'), index=False)\n",
    "stats_df.to_csv(os.path.join(output_dir, 'per_model_summary.csv'), index=False)\n",
    "feedback_df.to_csv(os.path.join(output_dir, 'feedback_report.csv'), index=False)\n",
    "if 'absa_df' in locals() and not absa_df.empty:\n",
    "    absa_df.to_csv(os.path.join(output_dir, 'absa_training_dataset.csv'), index=False)\n",
    "\n",
    "# Markdown report\n",
    "md_path = os.path.join(output_dir, 'manufacturer_recommendations.md')\n",
    "with open(md_path, 'w') as f:\n",
    "    f.write(\"# Manufacturer Feedback Report\\n\\n\")\n",
    "    for _, row in feedback_df.iterrows():\n",
    "        f.write(f\"## Model: {row['model']}\\n\")\n",
    "        f.write(f\"**Summary**: {row['summary']}\\n\\n\")\n",
    "        f.write(f\"**Strengths**: {row['strengths']}\\n\\n\")\n",
    "        f.write(f\"**Weaknesses**: {row['weaknesses']}\\n\\n\")\n",
    "        f.write(f\"**Recommendations**: {row['recommendations']}\\n\\n\")\n",
    "        f.write(\"---\\n\\n\")\n",
    "\n",
    "print(f\"Outputs saved to {output_dir}\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "491674d0",
   "metadata": {},
   "outputs": [],
   "source": [
    "# 9. Plots\n",
    "try:\n",
    "    plot_results(df, stats_df, plots_dir)\n",
    "    \n",
    "    # Display plots inline\n",
    "    print(\"Global Sentiment Distribution:\")\n",
    "    display(Image(filename=os.path.join(plots_dir, 'global_sentiment_distribution.png')))\n",
    "    \n",
    "    print(\"Per-Model Sentiment Count:\")\n",
    "    display(Image(filename=os.path.join(plots_dir, 'per_model_sentiment_count.png')))\n",
    "except Exception as e:\n",
    "    print(f\"Error plotting or displaying: {e}\")\n"
   ]
  }
 ],
 "metadata": {},
 "nbformat": 4,
 "nbformat_minor": 5
}
