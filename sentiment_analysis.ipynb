{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Sentiment Analysis & Feedback System\n",
    "\n",
    "This notebook implements a complete sentiment analysis pipeline for customer reviews.\n",
    "It performs:\n",
    "1. Data Loading & Cleaning\n",
    "2. Language Translation\n",
    "3. Duplicate Removal\n",
    "4. Sentiment Analysis (BERT)\n",
    "5. Aggregation & Reporting"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import os\n",
    "import sys\n",
    "import matplotlib.pyplot as plt\n",
    "from IPython.display import display, Image\n",
    "\n",
    "# Add current directory to path to import pipeline\n",
    "sys.path.append(os.getcwd())\n",
    "\n",
    "# Import functions from our pipeline script\n",
    "from sentiment_pipeline import (\n",
    "    load_data, preprocess_reviews, translate_and_clean, \n",
    "    handle_duplicates, analyze_sentiment, aggregate_model_stats, \n",
    "    generate_feedback_report, plot_results\n",
    ")\n",
    "\n",
    "%matplotlib inline"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# 1. Load Data\n",
    "dataset_path = 'final_dataset.csv'\n",
    "df = load_data(dataset_path)\n",
    "display(df.head())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# 2. Preprocess (Clean & Filter)\n",
    "df = preprocess_reviews(df)\n",
    "print(f\"Rows after cleaning: {len(df)}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# 3. Translate & Re-clean\n",
    "# This step might take time if using actual translation API\n",
    "df = translate_and_clean(df)\n",
    "display(df[['original_review', 'final_review']].head())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# 4. Handle Duplicates\n",
    "df = handle_duplicates(df)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# 5. Sentiment Analysis\n",
    "df = analyze_sentiment(df)\n",
    "display(df[['model', 'final_review', 'sentiment_label', 'sentiment_score']].head())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# 6. Aggregate Stats\n",
    "stats_df = aggregate_model_stats(df)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# 7. Generate Feedback Report\n",
    "feedback_df = generate_feedback_report(stats_df)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Display Summary Tables (Requirement 7)\n",
    "\n",
    "print(\"=== Model Summary ===\")\n",
    "display(stats_df.head(10))\n",
    "\n",
    "print(\"\\n=== Feedback Report ===\")\n",
    "display(feedback_df.head(10))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# 8. Save Outputs\n",
    "output_dir = 'outputs'\n",
    "plots_dir = os.path.join(output_dir, 'plots')\n",
    "os.makedirs(output_dir, exist_ok=True)\n",
    "\n",
    "df.to_csv(os.path.join(output_dir, 'sentiment_output.csv'), index=False)\n",
    "stats_df.to_csv(os.path.join(output_dir, 'per_model_summary.csv'), index=False)\n",
    "feedback_df.to_csv(os.path.join(output_dir, 'feedback_report.csv'), index=False)\n",
    "\n",
    "# Markdown report\n",
    "md_path = os.path.join(output_dir, 'manufacturer_recommendations.md')\n",
    "with open(md_path, 'w') as f:\n",
    "    f.write(\"# Manufacturer Feedback Report\\n\\n\")\n",
    "    for _, row in feedback_df.iterrows():\n",
    "        f.write(f\"## Model: {row['model']}\\n\")\n",
    "        f.write(f\"**Summary**: {row['summary']}\\n\\n\")\n",
    "        f.write(f\"**Strengths**: {row['strengths']}\\n\\n\")\n",
    "        f.write(f\"**Weaknesses**: {row['weaknesses']}\\n\\n\")\n",
    "        f.write(f\"**Recommendations**: {row['recommendations']}\\n\\n\")\n",
    "        f.write(\"---\\n\\n\")\n",
    "\n",
    "print(f\"Outputs saved to {output_dir}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# 9. Plots\n",
    "try:\n",
    "    plot_results(df, stats_df, plots_dir)\n",
    "    \n",
    "    # Display plots inline\n",
    "    print(\"Global Sentiment Distribution:\")\n",
    "    display(Image(filename=os.path.join(plots_dir, 'global_sentiment_distribution.png')))\n",
    "    \n",
    "    print(\"Per-Model Sentiment Count:\")\n",
    "    display(Image(filename=os.path.join(plots_dir, 'per_model_sentiment_count.png')))\n",
    "except Exception as e:\n",
    "    print(f\"Error plotting or displaying: {e}\")"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
